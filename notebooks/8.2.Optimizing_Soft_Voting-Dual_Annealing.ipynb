{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Optimized_soft_voting.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1YJfVs2JKYLdeHDemAoKzcM8dO_Ow8i7A","authorship_tag":"ABX9TyPKcEl3gRsccnZZONS18XyN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install xgboost --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"e9RYI8-dIFWZ","executionInfo":{"status":"ok","timestamp":1658564306610,"user_tz":420,"elapsed":20267,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"a1a965e5-bdc2-4377-ac60-e3d07315dc20"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Collecting xgboost\n","  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n","\u001b[K     |████████████████████████████████| 192.9 MB 56 kB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n","Installing collected packages: xgboost\n","  Attempting uninstall: xgboost\n","    Found existing installation: xgboost 0.90\n","    Uninstalling xgboost-0.90:\n","      Successfully uninstalled xgboost-0.90\n","Successfully installed xgboost-1.6.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["xgboost"]}}},"metadata":{}}]},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"7tqi-avAD_Sz"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","import os\n","import gc\n","\n","import xgboost as xgb\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score,balanced_accuracy_score, roc_auc_score\n","from sklearn.mixture import BayesianGaussianMixture\n","from sklearn.ensemble import ExtraTreesClassifier \n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","from scipy.optimize import dual_annealing\n","from numpy.random import rand\n"," \n","pd.options.display.max_rows = 100\n","pd.options.display.max_columns = 100"],"metadata":{"id":"Qlpb-mjGEK44","executionInfo":{"status":"ok","timestamp":1658564321059,"user_tz":420,"elapsed":975,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["class CFG:\n","    seed_bgm = 1\n","    seed = 42\n","    n_splits = 10\n","    n_clusters = 7\n","    threshold = 0.7\n","    PATH = 'drive/MyDrive/Kaggle/Clustering_072022/'"],"metadata":{"id":"9W-xE8wFEOpK","executionInfo":{"status":"ok","timestamp":1658564321060,"user_tz":420,"elapsed":8,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)"],"metadata":{"id":"xgrbkrxCEU_Z","executionInfo":{"status":"ok","timestamp":1658564321061,"user_tz":420,"elapsed":8,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(CFG.PATH + 'src/data.csv').drop('id', axis=1)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"GXzVhWPoEWbJ","executionInfo":{"status":"ok","timestamp":1658564322062,"user_tz":420,"elapsed":1008,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"7d611596-5548-4173-efc1-4ea3ee997f8f"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n","0     -0.389420 -0.912791  0.648951  0.589045 -0.830817  0.733624  2.258560   \n","1     -0.689249 -0.453954  0.654175  0.995248 -1.653020  0.863810 -0.090651   \n","2      0.809079  0.324568 -1.170602 -0.624491  0.105448  0.783948  1.988301   \n","3     -0.500923  0.229049  0.264109  0.231520  0.415012 -1.221269  0.138850   \n","4     -0.671268 -1.039533 -0.270155 -1.830264 -0.290108 -1.852809  0.781898   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","97995  0.237591  1.657034 -0.689282  0.313710 -0.299039  0.329139  1.607378   \n","97996  0.322696  0.710411  0.562625 -1.321713 -0.357708  0.182024  0.178558   \n","97997 -0.249364 -0.459545  1.886122 -1.340310  0.195029 -0.559520 -0.379767   \n","97998  0.311408  2.185237  0.761367  0.436723  0.464967  0.062321 -0.334025   \n","97999  0.755170  0.567483  1.456767 -0.579071 -0.048474 -1.206240  0.784305   \n","\n","       f_07  f_08  f_09  f_10  f_11  f_12  f_13      f_14      f_15      f_16  \\\n","0         2    13    14     5    13     6     6 -0.469819  0.358126  1.068105   \n","1         2     3     6     4     6    16     9  0.591035 -0.396915  0.145834   \n","2         5    11     5     8     9     3    11 -0.679875  0.469326  0.349843   \n","3         6     2    13     8     9     6     4 -0.389456  0.626762 -1.074543   \n","4         8     7     5     3     1    13    11 -0.120743 -0.615578 -1.064359   \n","...     ...   ...   ...   ...   ...   ...   ...       ...       ...       ...   \n","97995     5     7     8     5     7     6     7  0.362517  1.010965 -1.001519   \n","97996     3     9     2     5     3    11    12  0.683558 -1.238120  0.863433   \n","97997     8     9    10     7     5     4     3 -1.337303  0.064310  0.612507   \n","97998     1     8    11    11     3     9     5 -0.612314 -0.416691 -0.750458   \n","97999     0    11     3     8    16    13     5  0.457126  1.143457 -0.889129   \n","\n","           f_17      f_18      f_19      f_20      f_21      f_22      f_23  \\\n","0     -0.559650 -0.366905 -0.478412 -0.757002 -0.763635 -1.090369  1.142641   \n","1     -0.030798  0.471167 -0.428791 -0.089908 -1.784204 -0.839474  0.459685   \n","2     -0.288042  0.291470 -0.413534 -1.602377  1.190984  3.267116 -0.088322   \n","3     -1.521753 -1.150806  0.619283  1.287801  0.532837  1.036631 -2.041828   \n","4      0.444142  0.428327 -1.628830 -0.434948  0.322505  0.284326 -2.438365   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","97995  0.409882 -0.504114 -0.290116 -0.258141 -0.973640  1.369508  0.391055   \n","97996  1.318554 -1.125758  0.117687  1.388242  0.342400  1.680537 -0.860409   \n","97997  0.398968 -0.409608 -0.850223 -1.787648 -1.268115 -1.508330  1.945622   \n","97998  0.165038  0.333685 -0.010839  1.118906  1.565765  0.358480  0.547615   \n","97999 -0.201072 -1.095455  1.180805 -0.925705 -1.368680 -2.465425  1.453582   \n","\n","           f_24      f_25      f_26      f_27      f_28  \n","0     -0.884274  1.137896  1.309073  1.463002  0.813527  \n","1      1.759412 -0.275422 -0.852168  0.562457 -2.680541  \n","2     -2.168635 -0.974989  1.335763 -1.110655 -3.630723  \n","3      1.440490 -1.900191 -0.630771 -0.050641  0.238333  \n","4      1.473930 -1.044684  1.602686 -0.405263 -1.987263  \n","...         ...       ...       ...       ...       ...  \n","97995  2.152426 -0.208944 -1.475403  0.298448  0.445039  \n","97996  0.579165  1.162692  0.134994  0.994666  0.727642  \n","97997  1.503645  0.194968  2.142693  1.646042  0.641466  \n","97998  1.224439 -0.537998 -1.610954 -0.616227 -0.066211  \n","97999 -1.685122  0.129689 -0.970897  1.404988 -0.711098  \n","\n","[98000 rows x 29 columns]"],"text/html":["\n","  <div id=\"df-c04d5a0b-ca9c-414d-9981-7a6f3f85ade5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>f_00</th>\n","      <th>f_01</th>\n","      <th>f_02</th>\n","      <th>f_03</th>\n","      <th>f_04</th>\n","      <th>f_05</th>\n","      <th>f_06</th>\n","      <th>f_07</th>\n","      <th>f_08</th>\n","      <th>f_09</th>\n","      <th>f_10</th>\n","      <th>f_11</th>\n","      <th>f_12</th>\n","      <th>f_13</th>\n","      <th>f_14</th>\n","      <th>f_15</th>\n","      <th>f_16</th>\n","      <th>f_17</th>\n","      <th>f_18</th>\n","      <th>f_19</th>\n","      <th>f_20</th>\n","      <th>f_21</th>\n","      <th>f_22</th>\n","      <th>f_23</th>\n","      <th>f_24</th>\n","      <th>f_25</th>\n","      <th>f_26</th>\n","      <th>f_27</th>\n","      <th>f_28</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.389420</td>\n","      <td>-0.912791</td>\n","      <td>0.648951</td>\n","      <td>0.589045</td>\n","      <td>-0.830817</td>\n","      <td>0.733624</td>\n","      <td>2.258560</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>14</td>\n","      <td>5</td>\n","      <td>13</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>-0.469819</td>\n","      <td>0.358126</td>\n","      <td>1.068105</td>\n","      <td>-0.559650</td>\n","      <td>-0.366905</td>\n","      <td>-0.478412</td>\n","      <td>-0.757002</td>\n","      <td>-0.763635</td>\n","      <td>-1.090369</td>\n","      <td>1.142641</td>\n","      <td>-0.884274</td>\n","      <td>1.137896</td>\n","      <td>1.309073</td>\n","      <td>1.463002</td>\n","      <td>0.813527</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.689249</td>\n","      <td>-0.453954</td>\n","      <td>0.654175</td>\n","      <td>0.995248</td>\n","      <td>-1.653020</td>\n","      <td>0.863810</td>\n","      <td>-0.090651</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>16</td>\n","      <td>9</td>\n","      <td>0.591035</td>\n","      <td>-0.396915</td>\n","      <td>0.145834</td>\n","      <td>-0.030798</td>\n","      <td>0.471167</td>\n","      <td>-0.428791</td>\n","      <td>-0.089908</td>\n","      <td>-1.784204</td>\n","      <td>-0.839474</td>\n","      <td>0.459685</td>\n","      <td>1.759412</td>\n","      <td>-0.275422</td>\n","      <td>-0.852168</td>\n","      <td>0.562457</td>\n","      <td>-2.680541</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.809079</td>\n","      <td>0.324568</td>\n","      <td>-1.170602</td>\n","      <td>-0.624491</td>\n","      <td>0.105448</td>\n","      <td>0.783948</td>\n","      <td>1.988301</td>\n","      <td>5</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>-0.679875</td>\n","      <td>0.469326</td>\n","      <td>0.349843</td>\n","      <td>-0.288042</td>\n","      <td>0.291470</td>\n","      <td>-0.413534</td>\n","      <td>-1.602377</td>\n","      <td>1.190984</td>\n","      <td>3.267116</td>\n","      <td>-0.088322</td>\n","      <td>-2.168635</td>\n","      <td>-0.974989</td>\n","      <td>1.335763</td>\n","      <td>-1.110655</td>\n","      <td>-3.630723</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.500923</td>\n","      <td>0.229049</td>\n","      <td>0.264109</td>\n","      <td>0.231520</td>\n","      <td>0.415012</td>\n","      <td>-1.221269</td>\n","      <td>0.138850</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>-0.389456</td>\n","      <td>0.626762</td>\n","      <td>-1.074543</td>\n","      <td>-1.521753</td>\n","      <td>-1.150806</td>\n","      <td>0.619283</td>\n","      <td>1.287801</td>\n","      <td>0.532837</td>\n","      <td>1.036631</td>\n","      <td>-2.041828</td>\n","      <td>1.440490</td>\n","      <td>-1.900191</td>\n","      <td>-0.630771</td>\n","      <td>-0.050641</td>\n","      <td>0.238333</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.671268</td>\n","      <td>-1.039533</td>\n","      <td>-0.270155</td>\n","      <td>-1.830264</td>\n","      <td>-0.290108</td>\n","      <td>-1.852809</td>\n","      <td>0.781898</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>13</td>\n","      <td>11</td>\n","      <td>-0.120743</td>\n","      <td>-0.615578</td>\n","      <td>-1.064359</td>\n","      <td>0.444142</td>\n","      <td>0.428327</td>\n","      <td>-1.628830</td>\n","      <td>-0.434948</td>\n","      <td>0.322505</td>\n","      <td>0.284326</td>\n","      <td>-2.438365</td>\n","      <td>1.473930</td>\n","      <td>-1.044684</td>\n","      <td>1.602686</td>\n","      <td>-0.405263</td>\n","      <td>-1.987263</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>97995</th>\n","      <td>0.237591</td>\n","      <td>1.657034</td>\n","      <td>-0.689282</td>\n","      <td>0.313710</td>\n","      <td>-0.299039</td>\n","      <td>0.329139</td>\n","      <td>1.607378</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>0.362517</td>\n","      <td>1.010965</td>\n","      <td>-1.001519</td>\n","      <td>0.409882</td>\n","      <td>-0.504114</td>\n","      <td>-0.290116</td>\n","      <td>-0.258141</td>\n","      <td>-0.973640</td>\n","      <td>1.369508</td>\n","      <td>0.391055</td>\n","      <td>2.152426</td>\n","      <td>-0.208944</td>\n","      <td>-1.475403</td>\n","      <td>0.298448</td>\n","      <td>0.445039</td>\n","    </tr>\n","    <tr>\n","      <th>97996</th>\n","      <td>0.322696</td>\n","      <td>0.710411</td>\n","      <td>0.562625</td>\n","      <td>-1.321713</td>\n","      <td>-0.357708</td>\n","      <td>0.182024</td>\n","      <td>0.178558</td>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>0.683558</td>\n","      <td>-1.238120</td>\n","      <td>0.863433</td>\n","      <td>1.318554</td>\n","      <td>-1.125758</td>\n","      <td>0.117687</td>\n","      <td>1.388242</td>\n","      <td>0.342400</td>\n","      <td>1.680537</td>\n","      <td>-0.860409</td>\n","      <td>0.579165</td>\n","      <td>1.162692</td>\n","      <td>0.134994</td>\n","      <td>0.994666</td>\n","      <td>0.727642</td>\n","    </tr>\n","    <tr>\n","      <th>97997</th>\n","      <td>-0.249364</td>\n","      <td>-0.459545</td>\n","      <td>1.886122</td>\n","      <td>-1.340310</td>\n","      <td>0.195029</td>\n","      <td>-0.559520</td>\n","      <td>-0.379767</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>-1.337303</td>\n","      <td>0.064310</td>\n","      <td>0.612507</td>\n","      <td>0.398968</td>\n","      <td>-0.409608</td>\n","      <td>-0.850223</td>\n","      <td>-1.787648</td>\n","      <td>-1.268115</td>\n","      <td>-1.508330</td>\n","      <td>1.945622</td>\n","      <td>1.503645</td>\n","      <td>0.194968</td>\n","      <td>2.142693</td>\n","      <td>1.646042</td>\n","      <td>0.641466</td>\n","    </tr>\n","    <tr>\n","      <th>97998</th>\n","      <td>0.311408</td>\n","      <td>2.185237</td>\n","      <td>0.761367</td>\n","      <td>0.436723</td>\n","      <td>0.464967</td>\n","      <td>0.062321</td>\n","      <td>-0.334025</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>-0.612314</td>\n","      <td>-0.416691</td>\n","      <td>-0.750458</td>\n","      <td>0.165038</td>\n","      <td>0.333685</td>\n","      <td>-0.010839</td>\n","      <td>1.118906</td>\n","      <td>1.565765</td>\n","      <td>0.358480</td>\n","      <td>0.547615</td>\n","      <td>1.224439</td>\n","      <td>-0.537998</td>\n","      <td>-1.610954</td>\n","      <td>-0.616227</td>\n","      <td>-0.066211</td>\n","    </tr>\n","    <tr>\n","      <th>97999</th>\n","      <td>0.755170</td>\n","      <td>0.567483</td>\n","      <td>1.456767</td>\n","      <td>-0.579071</td>\n","      <td>-0.048474</td>\n","      <td>-1.206240</td>\n","      <td>0.784305</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>13</td>\n","      <td>5</td>\n","      <td>0.457126</td>\n","      <td>1.143457</td>\n","      <td>-0.889129</td>\n","      <td>-0.201072</td>\n","      <td>-1.095455</td>\n","      <td>1.180805</td>\n","      <td>-0.925705</td>\n","      <td>-1.368680</td>\n","      <td>-2.465425</td>\n","      <td>1.453582</td>\n","      <td>-1.685122</td>\n","      <td>0.129689</td>\n","      <td>-0.970897</td>\n","      <td>1.404988</td>\n","      <td>-0.711098</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>98000 rows × 29 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c04d5a0b-ca9c-414d-9981-7a6f3f85ade5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c04d5a0b-ca9c-414d-9981-7a6f3f85ade5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c04d5a0b-ca9c-414d-9981-7a6f3f85ade5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["all_scores = []\n","best_features = [f\"f_{i:02d}\" for i in list(range(7, 14)) + list(range(22, 29))]\n","features = df.columns\n","\n","def scores(preds, lib, df=df[best_features], verbose=True, compute_silhouette=None): \n","    # Silhouette is very slow\n","    sil = 0\n","    if compute_silhouette:\n","        sil = silhouette_score(df, preds, metric='euclidean')\n","    \n","    s = (lib,\n","         sil, \n","         calinski_harabasz_score(df, preds), \n","         davies_bouldin_score(df, preds))\n","    \n","    if verbose:\n","        print(f\"{s[0]} : Silhouette : {s[1]:.1%} | Calinski Harabasz : {s[2]:.1f} | Davis Bouldin : {s[3]:.3f}\")\n","        \n","    return s"],"metadata":{"id":"PCxaR7odEiLI","executionInfo":{"status":"ok","timestamp":1658564322065,"user_tz":420,"elapsed":11,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["seed_everything(CFG.seed_bgm)\n","df_scaled = pd.DataFrame(PowerTransformer().fit_transform(df[features]), columns=features)\n","\n","BGM = BayesianGaussianMixture(n_components=CFG.n_clusters, covariance_type='full', random_state=CFG.seed_bgm, max_iter=300, n_init=1, tol=1e-3)\n","BGM.fit(df_scaled[best_features])\n","\n","BGM_predict_proba = BGM.predict_proba(df_scaled[best_features])\n","BGM_predict = np.argmax(BGM_predict_proba, axis=1)\n","\n","all_scores.append(scores(BGM_predict, lib=\"BayesianGaussianMixture after powertransformer\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bdPpDMIdErwY","executionInfo":{"status":"ok","timestamp":1658564371759,"user_tz":420,"elapsed":49704,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"93b5c711-70c9-47d4-c3b4-d5849840652f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["BayesianGaussianMixture after powertransformer : Silhouette : 0.0% | Calinski Harabasz : 8156.3 | Davis Bouldin : 2.656\n"]}]},{"cell_type":"code","source":["# get trusted data to train LGB model.\n","proba_threshold = CFG.threshold\n","\n","df_scaled['predict'] = BGM_predict\n","df_scaled['predict_proba'] = 0\n","for n in range(CFG.n_clusters):\n","    df_scaled[f'predict_proba_{n}'] = BGM_predict_proba[:, n]\n","    df_scaled.loc[df_scaled['predict']==n, 'predict_proba'] = df_scaled[f'predict_proba_{n}']\n","    \n","    \n","idxs = np.array([])\n","for n in range(CFG.n_clusters):\n","    median = df_scaled[df_scaled.predict==n]['predict_proba'].median()\n","    idx = df_scaled[(df_scaled.predict==n) & (df_scaled.predict_proba > proba_threshold)].index\n","    idxs = np.concatenate((idxs, idx))\n","    print(f'Class n{n}  |  Median : {median:.4f}  |  Training data : {len(idx)/len(df_scaled[(df_scaled.predict==n)]):.1%}')\n","    \n","X = df_scaled.loc[idxs][best_features].reset_index(drop=True)\n","y = df_scaled.loc[idxs]['predict'].reset_index(drop=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-7K8qm0EuUY","executionInfo":{"status":"ok","timestamp":1658564371760,"user_tz":420,"elapsed":13,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"1ded150a-bc49-450e-8ebf-427b3e4452b2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Class n0  |  Median : 0.9116  |  Training data : 75.2%\n","Class n1  |  Median : 0.8669  |  Training data : 72.0%\n","Class n2  |  Median : 0.8685  |  Training data : 71.8%\n","Class n3  |  Median : 0.9074  |  Training data : 77.1%\n","Class n4  |  Median : 0.7312  |  Training data : 54.3%\n","Class n5  |  Median : 0.9833  |  Training data : 87.9%\n","Class n6  |  Median : 0.9376  |  Training data : 78.6%\n"]}]},{"cell_type":"code","source":["def get_score(labels, preds, probas):\n","    s = (balanced_accuracy_score(labels, preds),\n","        roc_auc_score(labels, probas, average=\"weighted\", multi_class=\"ovo\"))\n","    return s"],"metadata":{"id":"bYk_j41mExbZ","executionInfo":{"status":"ok","timestamp":1658564371761,"user_tz":420,"elapsed":10,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["params_xgb = {\n","    'booster': 'gbtree',\n","    'objective': 'multi:softprob',\n","    'learning_rate': 4e-2,\n","    'num_class': CFG.n_clusters,\n","    'seed': CFG.seed,\n","    'gpu_id': 0,\n","    'tree_method': 'gpu_hist',\n","    'predictor': 'gpu_predictor'\n","    }"],"metadata":{"id":"o-dJEHZgEy7J","executionInfo":{"status":"ok","timestamp":1658564371762,"user_tz":420,"elapsed":10,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["seed_everything(CFG.seed)\n","\n","xgb_predict_proba = 0\n","etc_predict_proba = 0\n","qda_predict_proba = 0\n","svc_predict_proba = 0\n","knc_predict_proba = 0\n","\n","classif_scores = []\n","\n","skf = StratifiedKFold(CFG.n_splits, shuffle=True, random_state=CFG.seed)\n","\n","for fold, (trn_idx, val_idx) in enumerate(skf.split(X, y)):\n","    print(f\"===== fold{fold} =====\")\n","    X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n","    X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n","    \n","        \n","    # XGBoost\n","    xgb_train = xgb.DMatrix(X_train, label=y_train)\n","    xgb_valid = xgb.DMatrix(X_valid, label=y_valid)\n","\n","    model = xgb.train(params_xgb,\n","                      dtrain=xgb_train,\n","                      evals=[(xgb_train, 'train'),(xgb_valid, 'eval')],\n","                      verbose_eval=False,\n","                      num_boost_round=20000,\n","                      early_stopping_rounds=200,\n","                     )\n","    \n","    y_pred_proba = model.predict(xgb_valid, iteration_range=(0, model.best_ntree_limit))\n","    y_pred = np.argmax(y_pred_proba, axis=1)\n","    \n","    s = get_score(y_valid, y_pred, y_pred_proba)\n","    print(f\"XGBoost    AUC : {s[1]:.3f} | Accuracy : {s[0]:.1%}\")\n","    classif_scores.append(s)\n","\n","    xgb_predict_proba += model.predict(\n","        xgb.DMatrix(df_scaled[best_features]),\n","        iteration_range=(0, model.best_ntree_limit)\n","    ) / CFG.n_splits\n","    \n","    del xgb_train, xgb_valid, model, s, y_pred, y_pred_proba\n","    gc.collect()\n","    \n","    # ExtraTreesClassifier\n","    model = ExtraTreesClassifier(n_estimators=1000, random_state=CFG.seed)\n","    model.fit(X_train, y_train)\n","    \n","    y_pred = model.predict(X_valid)\n","    y_pred_proba = model.predict_proba(X_valid)\n","    \n","    s = get_score(y_valid, y_pred, y_pred_proba)\n","    print(f\"ExtraTree  AUC : {s[1]:.3f} | Accuracy : {s[0]:.1%}\")\n","    classif_scores.append(s)\n","\n","    etc_predict_proba += model.predict_proba(df_scaled[best_features]) / CFG.n_splits\n","\n","    del model, s, y_pred, y_pred_proba\n","    gc.collect()\n","    \n","    # QuadraticDiscriminantAnalysis\n","    model = QuadraticDiscriminantAnalysis(priors=CFG.n_clusters)\n","    model.fit(X_train, y_train) # on trusted data only\n","    \n","    y_pred = model.predict(X_valid)\n","    y_pred_proba = model.predict_proba(X_valid)\n","    \n","    s = get_score(y_valid, y_pred, y_pred_proba)\n","    print(f\"QDA        AUC : {s[1]:.3f} | Accuracy : {s[0]:.1%}\")\n","    classif_scores.append(s)\n","\n","    qda_predict_proba += model.predict_proba(df_scaled[best_features]) / CFG.n_splits\n","\n","    del model, s, y_pred, y_pred_proba\n","    gc.collect()\n","\n","    # SVC\n","    model = SVC(probability=True)\n","    model.fit(X_train, y_train) # on trusted data only\n","    \n","    y_pred = model.predict(X_valid)\n","    y_pred_proba = model.predict_proba(X_valid)\n","    \n","    s = get_score(y_valid, y_pred, y_pred_proba)\n","    print(f\"SVC        AUC : {s[1]:.3f} | Accuracy : {s[0]:.1%}\")\n","    classif_scores.append(s)\n","\n","    svc_predict_proba += model.predict_proba(df_scaled[best_features]) / CFG.n_splits\n","\n","    del model, s, y_pred, y_pred_proba\n","    gc.collect()\n","\n","    # KNeighborsClassifier\n","    model = KNeighborsClassifier(n_neighbors=20)\n","    model.fit(X_train, y_train) # on trusted data only\n","    \n","    y_pred = model.predict(X_valid)\n","    y_pred_proba = model.predict_proba(X_valid)\n","    \n","    s = get_score(y_valid, y_pred, y_pred_proba)\n","    print(f\"KNeighbors AUC : {s[1]:.3f} | Accuracy : {s[0]:.1%}\")\n","    classif_scores.append(s)\n","\n","    knc_predict_proba += model.predict_proba(df_scaled[best_features]) / CFG.n_splits\n","\n","    del model, s, y_pred, y_pred_proba\n","    gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIeq4yaPE0ua","executionInfo":{"status":"ok","timestamp":1658569021259,"user_tz":420,"elapsed":1354057,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"87b53822-43a2-4575-e5de-934a49a3aaf1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["===== fold0 =====\n","XGBoost    AUC : 1.000 | Accuracy : 99.1%\n","ExtraTree  AUC : 0.999 | Accuracy : 96.4%\n","QDA        AUC : 1.000 | Accuracy : 99.9%\n","SVC        AUC : 1.000 | Accuracy : 99.7%\n","KNeighbors AUC : 0.999 | Accuracy : 97.4%\n","===== fold1 =====\n","XGBoost    AUC : 1.000 | Accuracy : 99.2%\n","ExtraTree  AUC : 0.999 | Accuracy : 97.2%\n","QDA        AUC : 1.000 | Accuracy : 100.0%\n","SVC        AUC : 1.000 | Accuracy : 99.8%\n","KNeighbors AUC : 1.000 | Accuracy : 97.6%\n","===== fold2 =====\n","XGBoost    AUC : 1.000 | Accuracy : 99.2%\n","ExtraTree  AUC : 0.999 | Accuracy : 96.5%\n","QDA        AUC : 1.000 | Accuracy : 100.0%\n","SVC        AUC : 1.000 | Accuracy : 99.8%\n","KNeighbors AUC : 1.000 | Accuracy : 97.2%\n","===== fold3 =====\n","XGBoost    AUC : 1.000 | Accuracy : 99.2%\n","ExtraTree  AUC : 0.999 | Accuracy : 96.5%\n","QDA        AUC : 1.000 | Accuracy : 99.9%\n","SVC        AUC : 1.000 | Accuracy : 99.8%\n","KNeighbors AUC : 1.000 | Accuracy : 97.4%\n","===== fold4 =====\n","XGBoost    AUC : 1.000 | Accuracy : 99.1%\n","ExtraTree  AUC : 0.999 | Accuracy : 96.4%\n","QDA        AUC : 1.000 | Accuracy : 99.9%\n","SVC        AUC : 1.000 | Accuracy : 99.8%\n","KNeighbors AUC : 1.000 | Accuracy : 97.3%\n","===== fold5 =====\n","XGBoost    AUC : 1.000 | Accuracy : 99.2%\n","ExtraTree  AUC : 0.999 | Accuracy : 96.3%\n","QDA        AUC : 1.000 | Accuracy : 100.0%\n","SVC        AUC : 1.000 | Accuracy : 99.8%\n","KNeighbors AUC : 1.000 | Accuracy : 97.3%\n","===== fold6 =====\n","XGBoost    AUC : 1.000 | Accuracy : 99.1%\n","ExtraTree  AUC : 0.999 | Accuracy : 96.8%\n","QDA        AUC : 1.000 | Accuracy : 99.9%\n","SVC        AUC : 1.000 | Accuracy : 99.8%\n","KNeighbors AUC : 1.000 | Accuracy : 97.9%\n","===== fold7 =====\n","XGBoost    AUC : 1.000 | Accuracy : 99.1%\n","ExtraTree  AUC : 0.999 | Accuracy : 96.3%\n","QDA        AUC : 1.000 | Accuracy : 99.9%\n","SVC        AUC : 1.000 | Accuracy : 99.8%\n","KNeighbors AUC : 1.000 | Accuracy : 96.9%\n","===== fold8 =====\n","XGBoost    AUC : 1.000 | Accuracy : 99.0%\n","ExtraTree  AUC : 0.999 | Accuracy : 96.4%\n","QDA        AUC : 1.000 | Accuracy : 99.9%\n","SVC        AUC : 1.000 | Accuracy : 99.8%\n","KNeighbors AUC : 1.000 | Accuracy : 97.6%\n","===== fold9 =====\n","XGBoost    AUC : 1.000 | Accuracy : 98.9%\n","ExtraTree  AUC : 0.999 | Accuracy : 96.3%\n","QDA        AUC : 1.000 | Accuracy : 100.0%\n","SVC        AUC : 1.000 | Accuracy : 99.8%\n","KNeighbors AUC : 1.000 | Accuracy : 97.3%\n"]}]},{"cell_type":"code","source":["def soft_voting(preds_probas, weights):\n","    pred_test = np.zeros((df.shape[0], CFG.n_clusters))\n","    \n","    for i, (p, w) in enumerate(zip(preds_probas, weights)):\n","        preds = np.argmax(p, axis=1)\n","        pred_idx = pd.Series(preds).value_counts().index.tolist()\n","        pred_test += p[:, pred_idx] * w\n","    \n","    return np.argmax(pred_test, axis=1)"],"metadata":{"id":"2RLxyBu0E4k5","executionInfo":{"status":"ok","timestamp":1658571267695,"user_tz":420,"elapsed":1078,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["for ITER in [25,50,75] :\n","\n","    # the weight evaluation function for weighting classifiers (blending coef) :\n","    def objective(w):\n","        w1, w2, w3, w4, w5 = w\n","\n","        sv_predict = soft_voting(\n","        [\n","         xgb_predict_proba, \n","         etc_predict_proba, \n","         qda_predict_proba, \n","         svc_predict_proba, \n","         knc_predict_proba],\n","        [w1, w2, w3, w4, w5])\n","        \n","        score = davies_bouldin_score(df, sv_predict)\n","\n","        return score\n","\n","    # the set of possible values of the variables (definition domain) :\n","    bounds = [[1, 100], \n","              [1, 100],  \n","              [1, 100], \n","              [1, 100], \n","              [1, 100]]\n","\n","    # the Dual Annealing optimization :\n","    result = dual_annealing(objective, bounds, maxiter = ITER, seed = 42 )\n","\n","    # results:\n","    print(f'\\n------------- maxiter:{ITER} -------------\\n')\n","    print('Success :', result['success'])\n","    print('Total Evaluations: %d' % result['nfev'])\n","\n","    solution = result['x']\n","    evaluation = objective(solution)\n","    print('Solution Weights : {} for minimum davies_bouldin_score = {}'.format((result['x'].astype(int)), evaluation))\n","\n","    sv_predict = soft_voting(\n","    [\n","     xgb_predict_proba, \n","     etc_predict_proba, \n","     qda_predict_proba, \n","     svc_predict_proba, \n","     knc_predict_proba],\n","    solution.tolist())\n","\n","    sub = pd.read_csv(CFG.PATH + \"submissions/sample_submission.csv\")\n","    sub['Predicted'] = sv_predict\n","    sub.to_csv(CFG.PATH + f\"submissions/optimized_soft_voting/submission_iter-{ITER}.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gd95PDmUE72x","executionInfo":{"status":"ok","timestamp":1658571427313,"user_tz":420,"elapsed":159269,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"cbeef68a-a8b1-4e69-bffe-1fc7fd6735ad"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","------------- maxiter:25 -------------\n","\n","Success : True\n","Total Evaluations: 287\n","Solution Weights : [ 1 94  7  4 65] for minimum davies_bouldin_score = 2.7396752695087256\n","\n","------------- maxiter:50 -------------\n","\n","Success : True\n","Total Evaluations: 537\n","Solution Weights : [ 1 94  7  4 65] for minimum davies_bouldin_score = 2.7396752695087256\n","\n","------------- maxiter:75 -------------\n","\n","Success : True\n","Total Evaluations: 787\n","Solution Weights : [ 1 94  7  4 65] for minimum davies_bouldin_score = 2.7396752695087256\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"dSGZsEA1E-xY"},"execution_count":null,"outputs":[]}]}